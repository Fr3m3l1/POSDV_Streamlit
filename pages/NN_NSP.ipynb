{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Date</th>\n",
       "      <th>SegFile</th>\n",
       "      <th>b</th>\n",
       "      <th>e</th>\n",
       "      <th>LBE</th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>...</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>AD</th>\n",
       "      <th>DE</th>\n",
       "      <th>LD</th>\n",
       "      <th>FS</th>\n",
       "      <th>SUSP</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Variab10.txt</td>\n",
       "      <td>01.12.1996</td>\n",
       "      <td>CTG0001.txt</td>\n",
       "      <td>240.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>03.05.1996</td>\n",
       "      <td>CTG0002.txt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>03.05.1996</td>\n",
       "      <td>CTG0003.txt</td>\n",
       "      <td>177.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>03.05.1996</td>\n",
       "      <td>CTG0004.txt</td>\n",
       "      <td>411.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FileName        Date      SegFile      b       e    LBE     LB   AC  \\\n",
       "0           NaN         NaN          NaN    NaN     NaN    NaN    NaN  NaN   \n",
       "1  Variab10.txt  01.12.1996  CTG0001.txt  240.0   357.0  120.0  120.0  0.0   \n",
       "2    Fmcs_1.txt  03.05.1996  CTG0002.txt    5.0   632.0  132.0  132.0  4.0   \n",
       "3    Fmcs_1.txt  03.05.1996  CTG0003.txt  177.0   779.0  133.0  133.0  2.0   \n",
       "4    Fmcs_1.txt  03.05.1996  CTG0004.txt  411.0  1192.0  134.0  134.0  2.0   \n",
       "\n",
       "    FM   UC  ...    C    D    E   AD   DE   LD   FS  SUSP  CLASS  NSP  \n",
       "0  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   NaN    NaN  NaN  \n",
       "1  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   0.0    9.0  2.0  \n",
       "2  0.0  4.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
       "3  0.0  5.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
       "4  0.0  6.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CSV file\n",
    "df = pd.read_csv('cardiotocography/raw_data.csv', delimiter=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>DP</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>...</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>133.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LB   AC   FM   UC   DL   DS   DP  ASTV  MSTV  ALTV  ...   Min    Max  \\\n",
       "0    NaN  NaN  NaN  NaN  NaN  NaN  NaN   NaN   NaN   NaN  ...   NaN    NaN   \n",
       "1  120.0  0.0  0.0  0.0  0.0  0.0  0.0  73.0   0.5  43.0  ...  62.0  126.0   \n",
       "2  132.0  4.0  0.0  4.0  2.0  0.0  0.0  17.0   2.1   0.0  ...  68.0  198.0   \n",
       "3  133.0  2.0  0.0  5.0  2.0  0.0  0.0  16.0   2.1   0.0  ...  68.0  198.0   \n",
       "4  134.0  2.0  0.0  6.0  2.0  0.0  0.0  16.0   2.4   0.0  ...  53.0  170.0   \n",
       "\n",
       "   Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  NSP  \n",
       "0   NaN     NaN    NaN    NaN     NaN       NaN       NaN  NaN  \n",
       "1   2.0     0.0  120.0  137.0   121.0      73.0       1.0  2.0  \n",
       "2   6.0     1.0  141.0  136.0   140.0      12.0       0.0  1.0  \n",
       "3   5.0     1.0  141.0  135.0   138.0      13.0       0.0  1.0  \n",
       "4  11.0     0.0  137.0  134.0   137.0      13.0       1.0  1.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean data\n",
    "# Extract relevant columns\n",
    "columns = [\n",
    "    'LB', 'AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'ASTV', 'MSTV', 'ALTV', 'MLTV', \n",
    "    'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 'Mode', 'Mean', 'Median', \n",
    "    'Variance', 'Tendency', 'NSP'\n",
    "]\n",
    "\n",
    "# Filter the dataset to include only these columns\n",
    "data_filtered = df[columns]\n",
    "\n",
    "data_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>DP</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>...</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>133.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LB   AC   FM   UC   DL   DS   DP  ASTV  MSTV  ALTV  ...   Min    Max  \\\n",
       "1  120.0  0.0  0.0  0.0  0.0  0.0  0.0  73.0   0.5  43.0  ...  62.0  126.0   \n",
       "2  132.0  4.0  0.0  4.0  2.0  0.0  0.0  17.0   2.1   0.0  ...  68.0  198.0   \n",
       "3  133.0  2.0  0.0  5.0  2.0  0.0  0.0  16.0   2.1   0.0  ...  68.0  198.0   \n",
       "4  134.0  2.0  0.0  6.0  2.0  0.0  0.0  16.0   2.4   0.0  ...  53.0  170.0   \n",
       "5  132.0  4.0  0.0  5.0  0.0  0.0  0.0  16.0   2.4   0.0  ...  53.0  170.0   \n",
       "\n",
       "   Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  NSP  \n",
       "1   2.0     0.0  120.0  137.0   121.0      73.0       1.0  2.0  \n",
       "2   6.0     1.0  141.0  136.0   140.0      12.0       0.0  1.0  \n",
       "3   5.0     1.0  141.0  135.0   138.0      13.0       0.0  1.0  \n",
       "4  11.0     0.0  137.0  134.0   137.0      13.0       1.0  1.0  \n",
       "5   9.0     0.0  137.0  136.0   138.0      11.0       1.0  1.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with missing values\n",
    "data_filtered = data_filtered.dropna()\n",
    "\n",
    "# Separate features and target\n",
    "X = data_filtered.drop('NSP', axis=1)\n",
    "y = data_filtered['NSP']\n",
    "\n",
    "# Display the first few rows of the filtered data\n",
    "data_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsAAAAIpCAYAAACsZI6lAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABA5UlEQVR4nO3de1hVZf7//9eWk0iwFVRwNyiYZzE1KlMrdTw2IpUVlQ3ZZGoehzykjmNaU1I2qVOWZWNSlkNzfQung4OiluUBM4zMU30qz4qY4UYMgXD9/ujnumYHmgd0b7ifj+va18W67/da672s3X65uvfCYVmWJQAAAMAQtbzdAAAAAHA5EYABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAHUeFu2bNGf/vQnxcbGqnbt2rriiit0zTXXaNasWfrxxx/tuu7du6t79+7ea/QMHA6H/fLz81O9evXUvn17DR8+XNnZ2RXqd+/eLYfDobS0tPM6z5IlSzR37tzz2qeyc82YMUMOh0M//PDDeR3rbLZv364ZM2Zo9+7dFeYeeOABxcTEVNm5ANR8BGAANdqrr76q+Ph4bdq0SRMnTlRmZqYyMjJ011136eWXX9aQIUO83eI5ufPOO7VhwwatXbtW6enpuv/++5Wdna3OnTvrz3/+s0dto0aNtGHDBvXv3/+8znEhAfhCz3W+tm/frscff7zSADxt2jRlZGRc0vMDqFn8vd0AAFwqGzZs0IgRI9S7d28tXbpUQUFB9lzv3r01fvx4ZWZmerHDcxcZGakbbrjB3u7bt69SUlI0bNgwPf/882rVqpVGjBghSQoKCvKovRTKy8v1888/X5Zz/ZarrrrKq+cHUP1wBxhAjTVz5kw5HA4tWLDAI/yeFhgYqMTExLMe4/HHH1enTp0UHh6usLAwXXPNNVq4cKEsy/KoW716tbp3766IiAgFBwercePGuuOOO/TTTz/ZNfPnz1f79u11xRVXKDQ0VK1atdJf/vKXC74+Pz8/zZs3T/Xr19ezzz5rj1e2LOHIkSMaNmyYoqOjFRQUpAYNGqhr165auXKlpF+Wf3z44Yfas2ePx5KL/z3erFmz9OSTTyo2NlZBQUH66KOPzrrcYt++fRo4cKDCwsLkdDr1xz/+UUeOHPGocTgcmjFjRoV9Y2Ji9MADD0iS0tLSdNddd0mSevToYfd2+pyVLYE4efKkpkyZotjYWAUGBurKK6/UqFGjdOzYsQrnSUhIUGZmpq655hoFBwerVatWeu21137jTx9AdcYdYAA1Unl5uVavXq34+HhFR0df8HF2796t4cOHq3HjxpKk7OxsjRkzRgcOHNBjjz1m1/Tv31833XSTXnvtNdWtW1cHDhxQZmamSktLVadOHaWnp2vkyJEaM2aM/v73v6tWrVr69ttvtX379ou6zuDgYPXq1Uvp6enav3+/fve731Val5ycrM2bN+upp55SixYtdOzYMW3evFlHjx6VJL300ksaNmyYvvvuuzMuJ3j++efVokUL/f3vf1dYWJiaN29+1t5uv/12JSUl6eGHH9a2bds0bdo0bd++XRs3blRAQMA5X2P//v01c+ZM/eUvf9GLL76oa665RtKZ7/xalqXbbrtNq1at0pQpU3TTTTdpy5Ytmj59ujZs2KANGzZ4/IXoyy+/1Pjx4zV58mRFRkbqn//8p4YMGaJmzZrp5ptvPuc+AVQfBGAANdIPP/ygn376SbGxsRd1nEWLFtk/nzp1St27d5dlWfrHP/6hadOmyeFwKCcnRydPntSzzz6r9u3b2/WDBg2yf163bp3q1q2r559/3h7r2bPnRfV2WpMmTSRJBw8ePGMAXrdunR566CENHTrUHrv11lvtn9u0aaO6deuedUlD7dq1tXz5co/wWtma3NMGDhyoWbNmSZL69OmjyMhI3Xffffr3v/+t++6775yvr0GDBnbYbtOmzW8uuVixYoWWL1+uWbNmaeLEiZJ+WfISHR2tu+++W2+88YbHn8MPP/ygdevW2X/Jufnmm7Vq1SotWbKEAAzUUCyBAICzWL16tXr16iWn0yk/Pz8FBAToscce09GjR5Wfny9J6tChgwIDAzVs2DC9/vrr+v777ysc5/rrr9exY8d077336j//+U+VPiHh18sxKnP99dcrLS1NTz75pLKzs1VWVnbe50lMTDyvO7e/DrlJSUny9/fXRx99dN7nPh+rV6+WJHsJxWl33XWXQkJCtGrVKo/xDh062OFX+iXot2jRQnv27LmkfQLwHgIwgBqpfv36qlOnjnbt2nXBx/jss8/Up08fSb88TWLdunXatGmTpk6dKkkqLi6W9Mv/il+5cqUaNmyoUaNG6aqrrtJVV12lf/zjH/axkpOT9dprr2nPnj2644471LBhQ3Xq1ElZWVkXcZW/OB3UXC7XGWvefvttDR48WP/85z/VuXNnhYeH6/7771deXt45n6dRo0bn1VdUVJTHtr+/vyIiIuxlF5fK0aNH5e/vrwYNGniMOxwORUVFVTh/REREhWMEBQXZ/3wB1DwEYAA1kp+fn3r27KmcnBzt37//go6Rnp6ugIAAffDBB0pKSlKXLl107bXXVlp700036f3335fb7bYfT5aSkqL09HS75k9/+pPWr18vt9utDz/8UJZlKSEh4aLuNBYXF2vlypW66qqrzrj8QfrlLwRz587V7t27tWfPHqWmpurdd9+tcJf0bE5/Ke5c/Tpc//zzzzp69KhH4AwKClJJSUmFfS8mJEdEROjnn3+u8IU7y7KUl5en+vXrX/CxAdQMBGAANdaUKVNkWZaGDh2q0tLSCvNlZWV6//33z7i/w+GQv7+//Pz87LHi4mItXrz4jPv4+fmpU6dOevHFFyVJmzdvrlATEhKiW265RVOnTlVpaam2bdt2PpdlKy8v1+jRo3X06FFNmjTpnPdr3LixRo8erd69e3v0V9V3Pd966y2P7X//+9/6+eefPX7ZSExMjLZs2eJRt3r1ahUVFXmMnf7S2rn0d3pt9Ztvvukx/s477+jEiRNVtvYaQPXFl+AA1FidO3fW/PnzNXLkSMXHx2vEiBFq27atysrK9MUXX2jBggWKi4vTgAEDKt2/f//+mj17tgYNGqRhw4bp6NGj+vvf/17hkWovv/yyVq9erf79+6tx48Y6efKk/RitXr16SZKGDh2q4OBgde3aVY0aNVJeXp5SU1PldDp13XXX/ea1HD58WNnZ2bIsS8ePH9fWrVv1xhtv6Msvv9Qjjzzi8aWuX3O73erRo4cGDRqkVq1aKTQ0VJs2bVJmZqYGDhxo17Vr107vvvuu5s+fr/j4eNWqVeuMd7zPxbvvvit/f3/17t3bfgpE+/btlZSUZNckJydr2rRpeuyxx9StWzdt375d8+bNk9Pp9DhWXFycJGnBggUKDQ1V7dq1FRsbW+nyhd69e6tv376aNGmSCgsL1bVrV/spEB07dlRycvIFXxOAGsICgBouNzfXGjx4sNW4cWMrMDDQCgkJsTp27Gg99thjVn5+vl3XrVs3q1u3bh77vvbaa1bLli2toKAgq2nTplZqaqq1cOFCS5K1a9cuy7Isa8OGDdbtt99uNWnSxAoKCrIiIiKsbt26We+99559nNdff93q0aOHFRkZaQUGBloul8tKSkqytmzZ8pv9S7JftWrVssLCwqx27dpZw4YNszZs2FChfteuXZYka9GiRZZlWdbJkyethx9+2Lr66qutsLAwKzg42GrZsqU1ffp068SJE/Z+P/74o3XnnXdadevWtRwOh3X6I+L08Z599tnfPJdlWdb06dMtSVZOTo41YMAA64orrrBCQ0Ote++91zp8+LDH/iUlJdajjz5qRUdHW8HBwVa3bt2s3Nxcq0mTJtbgwYM9aufOnWvFxsZafn5+HuccPHiw1aRJE4/a4uJia9KkSVaTJk2sgIAAq1GjRtaIESOsgoICj7omTZpY/fv3r3Bdlf27AKDmcFjWOXx9GAAAAKghWAMMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARuEXYZyjU6dO6eDBgwoNDT3vXwcKAACAS8/6/39ZkMvlUq1aZ77PSwA+RwcPHlR0dLS32wAAAMBv2Ldvn373u9+dcZ4AfI5CQ0Ml/fIHGhYW5uVuAAAA8GuFhYWKjo62c9uZEIDP0ellD2FhYQRgAAAAH/Zby1X5EhwAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADCKv7cbgHfETP7Q2y3gLHY/3d/bLQAAUGNxBxgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEbxagD+5JNPNGDAALlcLjkcDi1durRCzY4dO5SYmCin06nQ0FDdcMMN2rt3rz1fUlKiMWPGqH79+goJCVFiYqL279/vcYyCggIlJyfL6XTK6XQqOTlZx44du8RXBwAAAF/k1QB84sQJtW/fXvPmzat0/rvvvtONN96oVq1a6eOPP9aXX36padOmqXbt2nZNSkqKMjIylJ6errVr16qoqEgJCQkqLy+3awYNGqTc3FxlZmYqMzNTubm5Sk5OvuTXBwAAAN/jsCzL8nYTkuRwOJSRkaHbbrvNHrvnnnsUEBCgxYsXV7qP2+1WgwYNtHjxYt19992SpIMHDyo6OlrLli1T3759tWPHDrVp00bZ2dnq1KmTJCk7O1udO3fWzp071bJly3Pqr7CwUE6nU263W2FhYRd3sT4gZvKH3m4BZ7H76f7ebgEAgGrnXPOaz64BPnXqlD788EO1aNFCffv2VcOGDdWpUyePZRI5OTkqKytTnz597DGXy6W4uDitX79ekrRhwwY5nU47/ErSDTfcIKfTaddUpqSkRIWFhR4vAAAAVH8+G4Dz8/NVVFSkp59+Wv369dOKFSt0++23a+DAgVqzZo0kKS8vT4GBgapXr57HvpGRkcrLy7NrGjZsWOH4DRs2tGsqk5qaaq8Zdjqdio6OrsKrAwAAgLf4bAA+deqUJOnWW2/VI488og4dOmjy5MlKSEjQyy+/fNZ9LcuSw+Gwt//35zPV/NqUKVPkdrvt1759+y7wSgAAAOBLfDYA169fX/7+/mrTpo3HeOvWre2nQERFRam0tFQFBQUeNfn5+YqMjLRrDh8+XOH4R44csWsqExQUpLCwMI8XAAAAqj+fDcCBgYG67rrr9PXXX3uMf/PNN2rSpIkkKT4+XgEBAcrKyrLnDx06pK1bt6pLly6SpM6dO8vtduuzzz6zazZu3Ci3223XAAAAwBz+3jx5UVGRvv32W3t7165dys3NVXh4uBo3bqyJEyfq7rvv1s0336wePXooMzNT77//vj7++GNJktPp1JAhQzR+/HhFREQoPDxcEyZMULt27dSrVy9Jv9wx7tevn4YOHapXXnlFkjRs2DAlJCSc8xMgAAAAUHN4NQB//vnn6tGjh709btw4SdLgwYOVlpam22+/XS+//LJSU1M1duxYtWzZUu+8845uvPFGe585c+bI399fSUlJKi4uVs+ePZWWliY/Pz+75q233tLYsWPtp0UkJiae8dnDAAAAqNl85jnAvo7nAONy4jnAAACcv2r/HGAAAADgUiAAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYxasB+JNPPtGAAQPkcrnkcDi0dOnSM9YOHz5cDodDc+fO9RgvKSnRmDFjVL9+fYWEhCgxMVH79+/3qCkoKFBycrKcTqecTqeSk5N17Nixqr8gAAAA+DyvBuATJ06offv2mjdv3lnrli5dqo0bN8rlclWYS0lJUUZGhtLT07V27VoVFRUpISFB5eXlds2gQYOUm5urzMxMZWZmKjc3V8nJyVV+PQAAAPB9/t48+S233KJbbrnlrDUHDhzQ6NGjtXz5cvXv399jzu12a+HChVq8eLF69eolSXrzzTcVHR2tlStXqm/fvtqxY4cyMzOVnZ2tTp06SZJeffVVde7cWV9//bVatmxZ6XlLSkpUUlJibxcWFl7MpQIAAMBH+PQa4FOnTik5OVkTJ05U27ZtK8zn5OSorKxMffr0scdcLpfi4uK0fv16SdKGDRvkdDrt8CtJN9xwg5xOp11TmdTUVHvJhNPpVHR0dBVeGQAAALzFpwPwM888I39/f40dO7bS+by8PAUGBqpevXoe45GRkcrLy7NrGjZsWGHfhg0b2jWVmTJlitxut/3at2/fRVwJAAAAfIVXl0CcTU5Ojv7xj39o8+bNcjgc57WvZVke+1S2/69rfi0oKEhBQUHndV4AAAD4Pp+9A/zpp58qPz9fjRs3lr+/v/z9/bVnzx6NHz9eMTExkqSoqCiVlpaqoKDAY9/8/HxFRkbaNYcPH65w/CNHjtg1AAAAMIfPBuDk5GRt2bJFubm59svlcmnixIlavny5JCk+Pl4BAQHKysqy9zt06JC2bt2qLl26SJI6d+4st9utzz77zK7ZuHGj3G63XQMAAABzeHUJRFFRkb799lt7e9euXcrNzVV4eLgaN26siIgIj/qAgABFRUXZT25wOp0aMmSIxo8fr4iICIWHh2vChAlq166d/VSI1q1bq1+/fho6dKheeeUVSdKwYcOUkJBwxidAAAAAoObyagD+/PPP1aNHD3t73LhxkqTBgwcrLS3tnI4xZ84c+fv7KykpScXFxerZs6fS0tLk5+dn17z11lsaO3as/bSIxMTE33z2MAAAAGomh2VZlrebqA4KCwvldDrldrsVFhbm7XYuWszkD73dAs5i99P9f7sIAAB4ONe85rNrgAEAAIBLgQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKN4NQB/8sknGjBggFwulxwOh5YuXWrPlZWVadKkSWrXrp1CQkLkcrl0//336+DBgx7HKCkp0ZgxY1S/fn2FhIQoMTFR+/fv96gpKChQcnKynE6nnE6nkpOTdezYsctwhQAAAPA1Xg3AJ06cUPv27TVv3rwKcz/99JM2b96sadOmafPmzXr33Xf1zTffKDEx0aMuJSVFGRkZSk9P19q1a1VUVKSEhASVl5fbNYMGDVJubq4yMzOVmZmp3NxcJScnX/LrAwAAgO9xWJZlebsJSXI4HMrIyNBtt912xppNmzbp+uuv1549e9S4cWO53W41aNBAixcv1t133y1JOnjwoKKjo7Vs2TL17dtXO3bsUJs2bZSdna1OnTpJkrKzs9W5c2ft3LlTLVu2PKf+CgsL5XQ65Xa7FRYWdtHX620xkz/0dgs4i91P9/d2CwAAVDvnmteq1Rpgt9sth8OhunXrSpJycnJUVlamPn362DUul0txcXFav369JGnDhg1yOp12+JWkG264QU6n066pTElJiQoLCz1eAAAAqP6qTQA+efKkJk+erEGDBtmJPi8vT4GBgapXr55HbWRkpPLy8uyahg0bVjhew4YN7ZrKpKam2muGnU6noqOjq/BqAAAA4C3VIgCXlZXpnnvu0alTp/TSSy/9Zr1lWXI4HPb2//58pppfmzJlitxut/3at2/fhTUPAAAAn+LzAbisrExJSUnatWuXsrKyPNZzREVFqbS0VAUFBR775OfnKzIy0q45fPhwheMeOXLErqlMUFCQwsLCPF4AAACo/nw6AJ8Ov//3f/+nlStXKiIiwmM+Pj5eAQEBysrKsscOHTqkrVu3qkuXLpKkzp07y+1267PPPrNrNm7cKLfbbdcAAADAHP7ePHlRUZG+/fZbe3vXrl3Kzc1VeHi4XC6X7rzzTm3evFkffPCBysvL7TW74eHhCgwMlNPp1JAhQzR+/HhFREQoPDxcEyZMULt27dSrVy9JUuvWrdWvXz8NHTpUr7zyiiRp2LBhSkhIOOcnQAAAAKDm8GoA/vzzz9WjRw97e9y4cZKkwYMHa8aMGXrvvfckSR06dPDY76OPPlL37t0lSXPmzJG/v7+SkpJUXFysnj17Ki0tTX5+fnb9W2+9pbFjx9pPi0hMTKz02cMAAACo+XzmOcC+jucA43LiOcAAAJy/GvkcYAAAAOBiEYABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBSvBuBPPvlEAwYMkMvlksPh0NKlSz3mLcvSjBkz5HK5FBwcrO7du2vbtm0eNSUlJRozZozq16+vkJAQJSYmav/+/R41BQUFSk5OltPplNPpVHJyso4dO3aJrw4AAAC+yKsB+MSJE2rfvr3mzZtX6fysWbM0e/ZszZs3T5s2bVJUVJR69+6t48eP2zUpKSnKyMhQenq61q5dq6KiIiUkJKi8vNyuGTRokHJzc5WZmanMzEzl5uYqOTn5kl8fAAAAfI/DsizL201IksPhUEZGhm677TZJv9z9dblcSklJ0aRJkyT9crc3MjJSzzzzjIYPHy63260GDRpo8eLFuvvuuyVJBw8eVHR0tJYtW6a+fftqx44datOmjbKzs9WpUydJUnZ2tjp37qydO3eqZcuW59RfYWGhnE6n3G63wsLCqv4P4DKLmfyht1vAWex+ur+3WwAAoNo517zms2uAd+3apby8PPXp08ceCwoKUrdu3bR+/XpJUk5OjsrKyjxqXC6X4uLi7JoNGzbI6XTa4VeSbrjhBjmdTrumMiUlJSosLPR4AQAAoPrz2QCcl5cnSYqMjPQYj4yMtOfy8vIUGBioevXqnbWmYcOGFY7fsGFDu6Yyqamp9pphp9Op6Ojoi7oeAAAA+AafDcCnORwOj23LsiqM/dqvayqr/63jTJkyRW63237t27fvPDsHAACAL/LZABwVFSVJFe7S5ufn23eFo6KiVFpaqoKCgrPWHD58uMLxjxw5UuHu8v8KCgpSWFiYxwsAAADVn88G4NjYWEVFRSkrK8seKy0t1Zo1a9SlSxdJUnx8vAICAjxqDh06pK1bt9o1nTt3ltvt1meffWbXbNy4UW63264BAACAOfy9efKioiJ9++239vauXbuUm5ur8PBwNW7cWCkpKZo5c6aaN2+u5s2ba+bMmapTp44GDRokSXI6nRoyZIjGjx+viIgIhYeHa8KECWrXrp169eolSWrdurX69eunoUOH6pVXXpEkDRs2TAkJCef8BAgAAADUHF4NwJ9//rl69Ohhb48bN06SNHjwYKWlpenRRx9VcXGxRo4cqYKCAnXq1EkrVqxQaGiovc+cOXPk7++vpKQkFRcXq2fPnkpLS5Ofn59d89Zbb2ns2LH20yISExPP+OxhAAAA1Gw+8xxgX8dzgHE58RxgAADOX7V/DjAAAABwKRCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABglAsKwE2bNtXRo0crjB87dkxNmza96KYAAACAS+WCAvDu3btVXl5eYbykpEQHDhy46KYAAACAS8X/fIrfe+89++fly5fL6XTa2+Xl5Vq1apViYmKqrDkAAACgqp1XAL7tttskSQ6HQ4MHD/aYCwgIUExMjJ577rkqaw4AAACoaucVgE+dOiVJio2N1aZNm1S/fv1L0hQAAABwqZxXAD5t165dVd0HAAAAcFlcUACWpFWrVmnVqlXKz8+37wyf9tprr110YwAAAMClcEEB+PHHH9cTTzyha6+9Vo0aNZLD4ajqvgAAAIBL4oIC8Msvv6y0tDQlJydXdT8AAADAJXVBzwEuLS1Vly5dqroXAAAA4JK7oAD80EMPacmSJVXdCwAAAHDJXdASiJMnT2rBggVauXKlrr76agUEBHjMz549u0qaAwAAAKraBQXgLVu2qEOHDpKkrVu3eszxhTgAAAD4sgsKwB999FFV9wEAAABcFhe0BhgAAACori7oDnCPHj3OutRh9erVF9wQAAAAcCldUAA+vf73tLKyMuXm5mrr1q0aPHhwVfQFAAAAXBIXFIDnzJlT6fiMGTNUVFR0UQ0BAAAAl1KVrgH+4x//qNdee60qDwkAAABUqSoNwBs2bFDt2rWr8pAAAABAlbqgJRADBw702LYsS4cOHdLnn3+uadOmVUljAAAAwKVwQQHY6XR6bNeqVUstW7bUE088oT59+lRJYwAAAMClcEEBeNGiRVXdBwAAAHBZXFAAPi0nJ0c7duyQw+FQmzZt1LFjx6rqCwAAALgkLigA5+fn65577tHHH3+sunXryrIsud1u9ejRQ+np6WrQoEFV9wkAAABUiQt6CsSYMWNUWFiobdu26ccff1RBQYG2bt2qwsJCjR07tqp7BAAAAKrMBd0BzszM1MqVK9W6dWt7rE2bNnrxxRf5EhwAAAB82gXdAT516pQCAgIqjAcEBOjUqVMX3RQAAABwqVxQAP7973+vP//5zzp48KA9duDAAT3yyCPq2bNnlTUHAAAAVLULCsDz5s3T8ePHFRMTo6uuukrNmjVTbGysjh8/rhdeeKGqewQAAACqzAWtAY6OjtbmzZuVlZWlnTt3yrIstWnTRr169arq/gAAAIAqdV53gFevXq02bdqosLBQktS7d2+NGTNGY8eO1XXXXae2bdvq008/vSSNAgAAAFXhvALw3LlzNXToUIWFhVWYczqdGj58uGbPnl1lzf3888/661//qtjYWAUHB6tp06Z64oknPL5oZ1mWZsyYIZfLpeDgYHXv3l3btm3zOE5JSYnGjBmj+vXrKyQkRImJidq/f3+V9QkAAIDq47wC8Jdffql+/fqdcb5Pnz7Kycm56KZOe+aZZ/Tyyy9r3rx52rFjh2bNmqVnn33WY53xrFmzNHv2bM2bN0+bNm1SVFSUevfurePHj9s1KSkpysjIUHp6utauXauioiIlJCSovLy8ynoFAABA9XBea4APHz5c6ePP7IP5++vIkSMX3dRpGzZs0K233qr+/ftLkmJiYvSvf/1Ln3/+uaRf7v7OnTtXU6dO1cCBAyVJr7/+uiIjI7VkyRINHz5cbrdbCxcu1OLFi+01ym+++aaio6O1cuVK9e3bt8r6BQAAgO87rzvAV155pb766qszzm/ZskWNGjW66KZOu/HGG7Vq1Sp98803kn65A7127Vr94Q9/kCTt2rVLeXl5Hr98IygoSN26ddP69eslSTk5OSorK/OocblciouLs2sqU1JSosLCQo8XAAAAqr/zCsB/+MMf9Nhjj+nkyZMV5oqLizV9+nQlJCRUWXOTJk3Svffeq1atWikgIEAdO3ZUSkqK7r33XklSXl6eJCkyMtJjv8jISHsuLy9PgYGBqlev3hlrKpOamiqn02m/oqOjq+y6AAAA4D3ntQTir3/9q9599121aNFCo0ePVsuWLeVwOLRjxw69+OKLKi8v19SpU6usubfffltvvvmmlixZorZt2yo3N1cpKSlyuVwaPHiwXedwODz2syyrwtiv/VbNlClTNG7cOHu7sLCQEAwAAFADnFcAjoyM1Pr16zVixAhNmTJFlmVJ+iWA9u3bVy+99FKFu7EXY+LEiZo8ebLuueceSVK7du20Z88epaamavDgwYqKipL0y13e/116kZ+fb/cRFRWl0tJSFRQUeNwFzs/PV5cuXc547qCgIAUFBVXZtQAAAMA3nPdvgmvSpImWLVumH374QRs3blR2drZ++OEHLVu2TDExMVXa3E8//aRatTxb9PPzsx+DFhsbq6ioKGVlZdnzpaWlWrNmjR1u4+PjFRAQ4FFz6NAhbd269awBGAAAADXTBf0mOEmqV6+errvuuqrspYIBAwboqaeeUuPGjdW2bVt98cUXmj17th588EFJv9x5TklJ0cyZM9W8eXM1b95cM2fOVJ06dTRo0CBJvzyfeMiQIRo/frwiIiIUHh6uCRMmqF27dvzmOgAAAANdcAC+HF544QVNmzZNI0eOVH5+vlwul4YPH67HHnvMrnn00UdVXFyskSNHqqCgQJ06ddKKFSsUGhpq18yZM0f+/v5KSkpScXGxevbsqbS0NPn5+XnjsgAAAOBFDuv0Ql6cVWFhoZxOp9xud6W/Ca+6iZn8obdbwFnsfrq/t1sAAKDaOde8dt5rgAEAAIDqjAAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKP4fAA+cOCA/vjHPyoiIkJ16tRRhw4dlJOTY89blqUZM2bI5XIpODhY3bt317Zt2zyOUVJSojFjxqh+/foKCQlRYmKi9u/ff7kvBQAAAD7ApwNwQUGBunbtqoCAAP33v//V9u3b9dxzz6lu3bp2zaxZszR79mzNmzdPmzZtUlRUlHr37q3jx4/bNSkpKcrIyFB6errWrl2roqIiJSQkqLy83AtXBQAAAG9yWJZlebuJM5k8ebLWrVunTz/9tNJ5y7LkcrmUkpKiSZMmSfrlbm9kZKSeeeYZDR8+XG63Ww0aNNDixYt19913S5IOHjyo6OhoLVu2TH379j2nXgoLC+V0OuV2uxUWFlY1F+hFMZM/9HYLOIvdT/f3dgsAAFQ755rXfPoO8Hvvvadrr71Wd911lxo2bKiOHTvq1Vdfted37dqlvLw89enTxx4LCgpSt27dtH79eklSTk6OysrKPGpcLpfi4uLsmsqUlJSosLDQ4wUAAIDqz6cD8Pfff6/58+erefPmWr58uR5++GGNHTtWb7zxhiQpLy9PkhQZGemxX2RkpD2Xl5enwMBA1atX74w1lUlNTZXT6bRf0dHRVXlpAAAA8BKfDsCnTp3SNddco5kzZ6pjx44aPny4hg4dqvnz53vUORwOj23LsiqM/dpv1UyZMkVut9t+7du378IvBAAAAD7DpwNwo0aN1KZNG4+x1q1ba+/evZKkqKgoSapwJzc/P9++KxwVFaXS0lIVFBScsaYyQUFBCgsL83gBAACg+vPpANy1a1d9/fXXHmPffPONmjRpIkmKjY1VVFSUsrKy7PnS0lKtWbNGXbp0kSTFx8crICDAo+bQoUPaunWrXQMAAABz+Hu7gbN55JFH1KVLF82cOVNJSUn67LPPtGDBAi1YsEDSL0sfUlJSNHPmTDVv3lzNmzfXzJkzVadOHQ0aNEiS5HQ6NWTIEI0fP14REREKDw/XhAkT1K5dO/Xq1cublwcAAAAv8OkAfN111ykjI0NTpkzRE088odjYWM2dO1f33XefXfPoo4+quLhYI0eOVEFBgTp16qQVK1YoNDTUrpkzZ478/f2VlJSk4uJi9ezZU2lpafLz8/PGZQEAAMCLfPo5wL6E5wDjcuI5wAAAnL8a8RxgAAAAoKoRgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABglGoVgFNTU+VwOJSSkmKPWZalGTNmyOVyKTg4WN27d9e2bds89ispKdGYMWNUv359hYSEKDExUfv377/M3QMAAMAXVJsAvGnTJi1YsEBXX321x/isWbM0e/ZszZs3T5s2bVJUVJR69+6t48eP2zUpKSnKyMhQenq61q5dq6KiIiUkJKi8vPxyXwYAAAC8rFoE4KKiIt1333169dVXVa9ePXvcsizNnTtXU6dO1cCBAxUXF6fXX39dP/30k5YsWSJJcrvdWrhwoZ577jn16tVLHTt21JtvvqmvvvpKK1eu9NYlAQAAwEuqRQAeNWqU+vfvr169enmM79q1S3l5eerTp489FhQUpG7dumn9+vWSpJycHJWVlXnUuFwuxcXF2TWVKSkpUWFhoccLAAAA1Z+/txv4Lenp6dq8ebM2bdpUYS4vL0+SFBkZ6TEeGRmpPXv22DWBgYEed45P15zevzKpqal6/PHHL7Z9AAAA+BifvgO8b98+/fnPf9abb76p2rVrn7HO4XB4bFuWVWHs136rZsqUKXK73fZr375959c8AAAAfJJPB+CcnBzl5+crPj5e/v7+8vf315o1a/T888/L39/fvvP76zu5+fn59lxUVJRKS0tVUFBwxprKBAUFKSwszOMFAACA6s+nA3DPnj311VdfKTc3135de+21uu+++5Sbm6umTZsqKipKWVlZ9j6lpaVas2aNunTpIkmKj49XQECAR82hQ4e0detWuwYAAADm8Ok1wKGhoYqLi/MYCwkJUUREhD2ekpKimTNnqnnz5mrevLlmzpypOnXqaNCgQZIkp9OpIUOGaPz48YqIiFB4eLgmTJigdu3aVfhSHQAAAGo+nw7A5+LRRx9VcXGxRo4cqYKCAnXq1EkrVqxQaGioXTNnzhz5+/srKSlJxcXF6tmzp9LS0uTn5+fFzgEAAOANDsuyLG83UR0UFhbK6XTK7XbXiPXAMZM/9HYLOIvdT/f3dgsAAFQ755rXfHoNMAAAAFDVCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYxd/bDQBAdRIz+UNvt4Az2P10f2+3AKCa4A4wAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCg+HYBTU1N13XXXKTQ0VA0bNtRtt92mr7/+2qPGsizNmDFDLpdLwcHB6t69u7Zt2+ZRU1JSojFjxqh+/foKCQlRYmKi9u/ffzkvBQAAAD7CpwPwmjVrNGrUKGVnZysrK0s///yz+vTpoxMnTtg1s2bN0uzZszVv3jxt2rRJUVFR6t27t44fP27XpKSkKCMjQ+np6Vq7dq2KioqUkJCg8vJyb1wWAAAAvMjf2w2cTWZmpsf2okWL1LBhQ+Xk5Ojmm2+WZVmaO3eupk6dqoEDB0qSXn/9dUVGRmrJkiUaPny43G63Fi5cqMWLF6tXr16SpDfffFPR0dFauXKl+vbtW+m5S0pKVFJSYm8XFhZeoqsEAADA5eTTd4B/ze12S5LCw8MlSbt27VJeXp769Olj1wQFBalbt25av369JCknJ0dlZWUeNS6XS3FxcXZNZVJTU+V0Ou1XdHT0pbgkAAAAXGbVJgBblqVx48bpxhtvVFxcnCQpLy9PkhQZGelRGxkZac/l5eUpMDBQ9erVO2NNZaZMmSK3222/9u3bV5WXAwAAAC/x6SUQ/2v06NHasmWL1q5dW2HO4XB4bFuWVWHs136rJigoSEFBQRfWLAAAAHxWtbgDPGbMGL333nv66KOP9Lvf/c4ej4qKkqQKd3Lz8/Ptu8JRUVEqLS1VQUHBGWsAAABgDp8OwJZlafTo0Xr33Xe1evVqxcbGeszHxsYqKipKWVlZ9lhpaanWrFmjLl26SJLi4+MVEBDgUXPo0CFt3brVrgEAAIA5fHoJxKhRo7RkyRL95z//UWhoqH2n1+l0Kjg4WA6HQykpKZo5c6aaN2+u5s2ba+bMmapTp44GDRpk1w4ZMkTjx49XRESEwsPDNWHCBLVr185+KgQAAADM4dMBeP78+ZKk7t27e4wvWrRIDzzwgCTp0UcfVXFxsUaOHKmCggJ16tRJK1asUGhoqF0/Z84c+fv7KykpScXFxerZs6fS0tLk5+d3uS4FAAAAPsJhWZbl7Saqg8LCQjmdTrndboWFhXm7nYsWM/lDb7eAs9j9dH9vt4Az4L3ju3jf+DbeO76rJr13zjWv+fQaYAAAAKCqEYABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBSjAvBLL72k2NhY1a5dW/Hx8fr000+93RIAAAAuM2MC8Ntvv62UlBRNnTpVX3zxhW666Sbdcsst2rt3r7dbAwAAwGVkTACePXu2hgwZooceekitW7fW3LlzFR0drfnz53u7NQAAAFxG/t5u4HIoLS1VTk6OJk+e7DHep08frV+/vtJ9SkpKVFJSYm+73W5JUmFh4aVr9DI6VfKTt1vAWdSUf89qIt47vov3jW/jveO7atJ75/S1WJZ11jojAvAPP/yg8vJyRUZGeoxHRkYqLy+v0n1SU1P1+OOPVxiPjo6+JD0C/8s519sdANUP7xvgwtTE987x48fldDrPOG9EAD7N4XB4bFuWVWHstClTpmjcuHH29qlTp/Tjjz8qIiLijPvAOwoLCxUdHa19+/YpLCzM2+0A1QbvHeD88b7xbZZl6fjx43K5XGetMyIA169fX35+fhXu9ubn51e4K3xaUFCQgoKCPMbq1q17qVpEFQgLC+M/RsAF4L0DnD/eN77rbHd+TzPiS3CBgYGKj49XVlaWx3hWVpa6dOnipa4AAADgDUbcAZakcePGKTk5Wddee606d+6sBQsWaO/evXr44Ye93RoAAAAuI2MC8N13362jR4/qiSee0KFDhxQXF6dly5apSZMm3m4NFykoKEjTp0+vsGQFwNnx3gHOH++bmsFh/dZzIgAAAIAaxIg1wAAAAMBpBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxizGPQAAC/KC8v1w8//CCHw6GIiAj5+fl5uyUAuKy4A4xqrby8XIcPH1Z+fr7Ky8u93Q7g0zIyMtS1a1fVqVNHLpdLjRo1Up06ddS1a1ctXbrU2+0BPo/PnJqDAIxqiQ9y4Py88soruueee3T11Vfr7bff1tq1a/Xpp5/q7bff1tVXX6177rlHr776qrfbBHwSnzk1D78IA9XOK6+8orFjx+rBBx9U3759FRkZKcuylJ+fr+XLl2vRokV64YUXNHToUG+3CviMZs2aacqUKRoyZEil86+99pqeeuopfffdd5e5M8C38ZlTMxGAUe3wQQ6cv+DgYOXm5qply5aVzu/cuVMdO3ZUcXHxZe4M8G185tRMLIFAtXPgwAHdeOONZ5zv0qWLDh48eBk7Anxf27ZttWDBgjPOv/rqq2rbtu1l7AioHvjMqZl4CgSqndMf5M8991yl83yQAxU999xz6t+/vzIzM9WnTx9FRkbK4XAoLy9PWVlZ2rNnj5YtW+btNgGfw2dOzcQSCFQ7a9asUf/+/dWkSZOzfpDfdNNN3m4V8Cm7d+/W/PnzlZ2drby8PElSVFSUOnfurIcfflgxMTHebRDwQXzm1EwEYFRLfJADAC4XPnNqHgIwAAAAjMKX4AAAGjx4sH7/+997uw0AuCwIwKhx+CAHzt+VV16pJk2aeLsNoNrhM6d64ikQqHFcLpdq1eLvdsD5mDlzprdbAKolPnOqJ9YAAwAAwCj8lQU1zr59+/Tggw96uw3A5xQXF2vt2rXavn17hbmTJ0/qjTfe8EJXgO/bsWOHFi1apJ07d0r65TcnjhgxQg8++KBWr17t5e5wIbgDjBrnyy+/1DXXXKPy8nJvtwL4jG+++UZ9+vTR3r175XA4dNNNN+lf//qXGjVqJEk6fPiwXC4X7xvgVzIzM3Xrrbfqiiuu0E8//aSMjAzdf//9at++vSzL0po1a7R8+XLWAVczBGBUO++9995Z57///nuNHz+eD3Lgf9x+++36+eeftWjRIh07dkzjxo3T1q1b9fHHH6tx48YEYOAMunTpot///vd68sknlZ6erpEjR2rEiBF66qmnJElTp07Vpk2btGLFCi93ivNBAEa1U6tWLTkcDp3tX12Hw8EHOfA/IiMjtXLlSrVr184eGzVqlD744AN99NFHCgkJIQADlXA6ncrJyVGzZs106tQpBQUFaePGjbrmmmskSVu3blWvXr3sX5CB6oE1wKh2GjVqpHfeeUenTp2q9LV582Zvtwj4nOLiYvn7ez7458UXX1RiYqK6deumb775xkudAdVHrVq1VLt2bdWtW9ceCw0Nldvt9l5TuCAEYFQ78fHxZw25v3V3GDBRq1at9Pnnn1cYf+GFF3TrrbcqMTHRC10Bvi8mJkbffvutvb1hwwY1btzY3t63b5+9lh7VBwEY1c7EiRPVpUuXM843a9ZMH3300WXsCPB9t99+u/71r39VOjdv3jzde++9/MURqMSIESM8lgbFxcV5/N+U//73v3wBrhpiDTAAAACMwh1gAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAJyVw+HQ0qVLvd0GAFQZAjAAeMkDDzwgh8Ohp59+2mN86dKlcjgcHmOvvPKK2rdvr5CQENWtW1cdO3bUM888Y8/PmDFDDodDDodDfn5+io6O1kMPPaQjR46ctYe8vDyNGTNGTZs2VVBQkKKjozVgwACtWrWq6i4UAHyM/2+XAAAuldq1a+uZZ57R8OHDVa9evUprFi5cqHHjxun5559Xt27dVFJSoi1btmj79u0edW3bttXKlStVXl6uL774QkOGDNGBAwf03//+t9Lj7t69W127dlXdunU1a9YsXX311SorK9Py5cs1atQo7dy5s8qvFwB8AXeAAcCLevXqpaioKKWmpp6x5v3331dSUpKGDBmiZs2aqW3btrr33nv1t7/9zaPO399fUVFRuvLKK5WQkKCxY8dqxYoVKi4urvS4I0eOlMPh0GeffaY777xTLVq0UNu2bTVu3DhlZ2efsZ9JkyapRYsWqlOnjpo2bapp06aprKzMnv/yyy/Vo0cPhYaGKiwsTPHx8fZvoduzZ48GDBigevXqKSQkRG3bttWyZcvO548MAC4ad4ABwIv8/Pw0c+ZMDRo0SGPHjtXvfve7CjVRUVFas2aN9uzZoyZNmpzzsYODg3Xq1Cn9/PPPFeZ+/PFHZWZm6qmnnlJISEiF+bp1657xuKGhoUpLS5PL5dJXX32loUOHKjQ0VI8++qgk6b777lPHjh01f/58+fn5KTc3VwEBAZKkUaNGqbS0VJ988olCQkK0fft2XXHFFed8TQBQFQjAAOBlt99+uzp06KDp06dr4cKFFeanT5+ugQMHKiYmRi1atFDnzp31hz/8QXfeeadq1ar8f+Tt3LlT8+fP1/XXX6/Q0NAK899++60sy1KrVq3Ou9+//vWv9s8xMTEaP3683n77bTsA7927VxMnTrSP3bx5c7t+7969uuOOO9SuXTtJUtOmTc/7/ABwsVgCAQA+4JlnntHrr79eYV2vJDVq1EgbNmzQV199pbFjx6qsrEyDBw9Wv379dOrUKbvuq6++0hVXXKHg4GC1adNG0dHReuuttyo9n2VZklThy3bn4v/9v/+nG2+8UVFRUbriiis0bdo07d27154fN26cHnroIfXq1UtPP/20vvvuO3tu7NixevLJJ9W1a1dNnz5dW7ZsOe/zA8DFIgADgA+4+eab1bdvX/3lL385Y01cXJxGjRqlt956S1lZWcrKytKaNWvs+ZYtWyo3N1fbt29XcXGxVq9erWbNmlV6rObNm8vhcGjHjh3n1Wd2drbuuece3XLLLfrggw/0xRdfaOrUqSotLbVrZsyYoW3btql///5avXq12rRpo4yMDEnSQw89pO+//17Jycn66quvdO211+qFF144rx4A4GIRgAHARzz99NN6//33tX79+t+sbdOmjSTpxIkT9lhgYKCaNWum2NhYBQUFnXX/8PBw9e3bVy+++KLHMU47duxYpfutW7dOTZo00dSpU3XttdeqefPm2rNnT4W6Fi1a6JFHHtGKFSs0cOBALVq0yJ6Ljo7Www8/rHfffVfjx4/Xq6+++pvXCwBViQAMAD6iXbt2uu+++yrcER0xYoT+9re/ad26ddqzZ4+ys7N1//33q0GDBurcufMFn++ll15SeXm5rr/+er3zzjv6v//7P+3YsUPPP//8GY/brFkz7d27V+np6fruu+/0/PPP23d3Jam4uFijR4/Wxx9/rD179mjdunXatGmTWrduLUlKSUnR8uXLtWvXLm3evFmrV6+25wDgciEAA4AP+dvf/mavzz2tV69eys7O1l133aUWLVrojjvuUO3atbVq1SpFRERc8LliY2O1efNm9ejRQ+PHj1dcXJx69+6tVatWaf78+ZXuc+utt+qRRx7R6NGj1aFDB61fv17Tpk2z5/38/HT06FHdf//9atGihZKSknTLLbfo8ccflySVl5dr1KhRat26tfr166eWLVvqpZdeuuBrAIAL4bB+/V9aAAAAoAbjDjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwyv8HWYr5T/QkYCYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "y.value_counts().plot(kind='bar')\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('NSP Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\noiri\\.conda\\envs\\brain_tumor\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5500 - loss: 0.8482 - val_accuracy: 0.7673 - val_loss: 0.4873\n",
      "Epoch 2/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8417 - loss: 0.4161 - val_accuracy: 0.9145 - val_loss: 0.2571\n",
      "Epoch 3/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2485 - val_accuracy: 0.9296 - val_loss: 0.2183\n",
      "Epoch 4/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9209 - loss: 0.2213 - val_accuracy: 0.9258 - val_loss: 0.2030\n",
      "Epoch 5/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9364 - loss: 0.1818 - val_accuracy: 0.9421 - val_loss: 0.1670\n",
      "Epoch 6/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.1544 - val_accuracy: 0.9497 - val_loss: 0.1522\n",
      "Epoch 7/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9549 - loss: 0.1351 - val_accuracy: 0.9522 - val_loss: 0.1336\n",
      "Epoch 8/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9634 - loss: 0.1192 - val_accuracy: 0.9497 - val_loss: 0.1487\n",
      "Epoch 9/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9649 - loss: 0.1065 - val_accuracy: 0.9572 - val_loss: 0.1253\n",
      "Epoch 10/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9626 - loss: 0.1107 - val_accuracy: 0.9547 - val_loss: 0.1259\n",
      "Epoch 11/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9666 - loss: 0.1043 - val_accuracy: 0.9648 - val_loss: 0.1244\n",
      "Epoch 12/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9766 - loss: 0.0797 - val_accuracy: 0.9597 - val_loss: 0.1113\n",
      "Epoch 13/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9743 - loss: 0.0795 - val_accuracy: 0.9648 - val_loss: 0.1088\n",
      "Epoch 14/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9778 - loss: 0.0763 - val_accuracy: 0.9686 - val_loss: 0.1054\n",
      "Epoch 15/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0652 - val_accuracy: 0.9698 - val_loss: 0.1162\n",
      "Epoch 16/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9760 - loss: 0.0710 - val_accuracy: 0.9635 - val_loss: 0.1178\n",
      "Epoch 17/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.0767 - val_accuracy: 0.9673 - val_loss: 0.1046\n",
      "Epoch 18/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9766 - loss: 0.0660 - val_accuracy: 0.9761 - val_loss: 0.0939\n",
      "Epoch 19/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0610 - val_accuracy: 0.9711 - val_loss: 0.1080\n",
      "Epoch 20/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0524 - val_accuracy: 0.9723 - val_loss: 0.0950\n",
      "Epoch 21/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.0637 - val_accuracy: 0.9711 - val_loss: 0.1047\n",
      "Epoch 22/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9806 - loss: 0.0560 - val_accuracy: 0.9686 - val_loss: 0.0983\n",
      "Epoch 23/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.0541 - val_accuracy: 0.9748 - val_loss: 0.1036\n",
      "Epoch 24/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0423 - val_accuracy: 0.9711 - val_loss: 0.1072\n",
      "Epoch 25/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0587 - val_accuracy: 0.9748 - val_loss: 0.0932\n",
      "Epoch 26/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0425 - val_accuracy: 0.9711 - val_loss: 0.1034\n",
      "Epoch 27/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.0431 - val_accuracy: 0.9786 - val_loss: 0.0886\n",
      "Epoch 28/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0331 - val_accuracy: 0.9786 - val_loss: 0.0923\n",
      "Epoch 29/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9864 - loss: 0.0429 - val_accuracy: 0.9723 - val_loss: 0.1085\n",
      "Epoch 30/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9900 - loss: 0.0346 - val_accuracy: 0.9786 - val_loss: 0.0953\n",
      "Epoch 31/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0419 - val_accuracy: 0.9799 - val_loss: 0.0923\n",
      "Epoch 32/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0374 - val_accuracy: 0.9660 - val_loss: 0.1093\n",
      "Epoch 33/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9870 - loss: 0.0355 - val_accuracy: 0.9748 - val_loss: 0.0893\n",
      "Epoch 34/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0432 - val_accuracy: 0.9761 - val_loss: 0.0933\n",
      "Epoch 35/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9877 - loss: 0.0310 - val_accuracy: 0.9774 - val_loss: 0.0997\n",
      "Epoch 36/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0286 - val_accuracy: 0.9774 - val_loss: 0.0955\n",
      "Epoch 37/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0236 - val_accuracy: 0.9786 - val_loss: 0.0872\n",
      "Epoch 38/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0268 - val_accuracy: 0.9748 - val_loss: 0.1069\n",
      "Epoch 39/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0225 - val_accuracy: 0.9748 - val_loss: 0.1120\n",
      "Epoch 40/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0202 - val_accuracy: 0.9761 - val_loss: 0.0904\n",
      "Epoch 41/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0222 - val_accuracy: 0.9786 - val_loss: 0.1006\n",
      "Epoch 42/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9895 - loss: 0.0227 - val_accuracy: 0.9736 - val_loss: 0.1250\n",
      "Epoch 43/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0293 - val_accuracy: 0.9774 - val_loss: 0.0827\n",
      "Epoch 44/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9957 - loss: 0.0136 - val_accuracy: 0.9786 - val_loss: 0.0970\n",
      "Epoch 45/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0284 - val_accuracy: 0.9786 - val_loss: 0.0944\n",
      "Epoch 46/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0191 - val_accuracy: 0.9748 - val_loss: 0.0999\n",
      "Epoch 47/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0266 - val_accuracy: 0.9761 - val_loss: 0.0990\n",
      "Epoch 48/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0214 - val_accuracy: 0.9799 - val_loss: 0.1167\n",
      "Epoch 49/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9967 - loss: 0.0124 - val_accuracy: 0.9799 - val_loss: 0.0977\n",
      "Epoch 50/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0224 - val_accuracy: 0.9786 - val_loss: 0.1088\n",
      "Epoch 51/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0203 - val_accuracy: 0.9786 - val_loss: 0.1285\n",
      "Epoch 52/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0197 - val_accuracy: 0.9824 - val_loss: 0.1000\n",
      "Epoch 53/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0205 - val_accuracy: 0.9786 - val_loss: 0.0975\n",
      "Epoch 54/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9939 - loss: 0.0200 - val_accuracy: 0.9786 - val_loss: 0.1087\n",
      "Epoch 55/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0224 - val_accuracy: 0.9786 - val_loss: 0.1128\n",
      "Epoch 56/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0261 - val_accuracy: 0.9811 - val_loss: 0.1207\n",
      "Epoch 57/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0116 - val_accuracy: 0.9811 - val_loss: 0.1150\n",
      "Epoch 58/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0235 - val_accuracy: 0.9748 - val_loss: 0.1257\n",
      "Epoch 59/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9906 - loss: 0.0286 - val_accuracy: 0.9786 - val_loss: 0.1054\n",
      "Epoch 60/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0127 - val_accuracy: 0.9799 - val_loss: 0.1100\n",
      "Epoch 61/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0150 - val_accuracy: 0.9799 - val_loss: 0.1248\n",
      "Epoch 62/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9951 - loss: 0.0141 - val_accuracy: 0.9786 - val_loss: 0.1368\n",
      "Epoch 63/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9944 - loss: 0.0156 - val_accuracy: 0.9811 - val_loss: 0.1332\n",
      "Epoch 64/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0224 - val_accuracy: 0.9799 - val_loss: 0.1069\n",
      "Epoch 65/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9953 - loss: 0.0124 - val_accuracy: 0.9824 - val_loss: 0.1098\n",
      "Epoch 66/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9935 - loss: 0.0166 - val_accuracy: 0.9673 - val_loss: 0.1362\n",
      "Epoch 67/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0123 - val_accuracy: 0.9698 - val_loss: 0.1199\n",
      "Epoch 68/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9945 - loss: 0.0164 - val_accuracy: 0.9774 - val_loss: 0.1346\n",
      "Epoch 69/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0209 - val_accuracy: 0.9786 - val_loss: 0.1117\n",
      "Epoch 70/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9935 - loss: 0.0185 - val_accuracy: 0.9824 - val_loss: 0.1317\n",
      "Epoch 71/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9960 - loss: 0.0121 - val_accuracy: 0.9748 - val_loss: 0.1358\n",
      "Epoch 72/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9914 - loss: 0.0141 - val_accuracy: 0.9786 - val_loss: 0.1352\n",
      "Epoch 73/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0156 - val_accuracy: 0.9786 - val_loss: 0.1291\n",
      "Epoch 74/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0175 - val_accuracy: 0.9774 - val_loss: 0.1142\n",
      "Epoch 75/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0321 - val_accuracy: 0.9774 - val_loss: 0.1566\n",
      "Epoch 76/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0198 - val_accuracy: 0.9824 - val_loss: 0.1409\n",
      "Epoch 77/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0063 - val_accuracy: 0.9811 - val_loss: 0.1407\n",
      "Epoch 78/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9944 - loss: 0.0183 - val_accuracy: 0.9786 - val_loss: 0.1013\n",
      "Epoch 79/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9943 - loss: 0.0112 - val_accuracy: 0.9824 - val_loss: 0.1154\n",
      "Epoch 80/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0063 - val_accuracy: 0.9736 - val_loss: 0.1462\n",
      "Epoch 81/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0106 - val_accuracy: 0.9824 - val_loss: 0.1442\n",
      "Epoch 82/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0083 - val_accuracy: 0.9736 - val_loss: 0.2006\n",
      "Epoch 83/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0383 - val_accuracy: 0.9824 - val_loss: 0.1499\n",
      "Epoch 84/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9872 - loss: 0.0390 - val_accuracy: 0.9723 - val_loss: 0.1488\n",
      "Epoch 85/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0258 - val_accuracy: 0.9748 - val_loss: 0.1502\n",
      "Epoch 86/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0127 - val_accuracy: 0.9761 - val_loss: 0.1093\n",
      "Epoch 87/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0103 - val_accuracy: 0.9836 - val_loss: 0.1191\n",
      "Epoch 88/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0108 - val_accuracy: 0.9824 - val_loss: 0.1489\n",
      "Epoch 89/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0087 - val_accuracy: 0.9786 - val_loss: 0.1293\n",
      "Epoch 90/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0109 - val_accuracy: 0.9836 - val_loss: 0.1129\n",
      "Epoch 91/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0086 - val_accuracy: 0.9761 - val_loss: 0.1491\n",
      "Epoch 92/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0193 - val_accuracy: 0.9774 - val_loss: 0.1593\n",
      "Epoch 93/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9937 - loss: 0.0195 - val_accuracy: 0.9811 - val_loss: 0.1584\n",
      "Epoch 94/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0063 - val_accuracy: 0.9786 - val_loss: 0.1267\n",
      "Epoch 95/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0216 - val_accuracy: 0.9786 - val_loss: 0.1388\n",
      "Epoch 96/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0052 - val_accuracy: 0.9811 - val_loss: 0.1366\n",
      "Epoch 97/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9976 - loss: 0.0094 - val_accuracy: 0.9786 - val_loss: 0.1164\n",
      "Epoch 98/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9953 - loss: 0.0161 - val_accuracy: 0.9811 - val_loss: 0.1388\n",
      "Epoch 99/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9961 - loss: 0.0116 - val_accuracy: 0.9824 - val_loss: 0.1176\n",
      "Epoch 100/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9937 - loss: 0.0123 - val_accuracy: 0.9836 - val_loss: 0.1414\n"
     ]
    }
   ],
   "source": [
    "X = data_filtered.drop('NSP', axis=1)\n",
    "y = data_filtered['NSP']\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Convert target to categorical\n",
    "y_train = tf.keras.utils.to_categorical(y_train - 1, num_classes=3)\n",
    "y_test = tf.keras.utils.to_categorical(y_test - 1, num_classes=3)\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2, batch_size=32, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to nsp_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model to a HDF5 file\n",
    "model.save('nsp_model.h5')\n",
    "model.save('nsp_model.keras')\n",
    "print(\"Model saved to nsp_model.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "posdv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
